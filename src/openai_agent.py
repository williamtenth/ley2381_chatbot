import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
import json
from datetime import datetime
from dataclasses import dataclass
import openai
from loguru import logger

# Agregar el directorio ra√≠z al path
sys.path.append(str(Path(__file__).parent.parent))

from config.settings import settings
from src.vector_store import LawVectorStore

@dataclass
class QueryResult:
    """Resultado de una consulta al agente"""
    response: str
    sources: List[Dict[str, Any]]
    query: str
    timestamp: datetime
    processing_time: float

class OpenAIAgent:
    def __init__(self):
        # Verificar API key antes de crear el cliente
        if not settings.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY no configurada. Revisa tu archivo .env")
        
        try:
            self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
            logger.info("Cliente de OpenAI inicializado correctamente")
        except Exception as e:
            logger.error(f"Error inicializando cliente OpenAI: {e}")
            raise
            
        self.vector_store = LawVectorStore()
        self.conversation_cache = {}
        
        # Verificar que el vector store est√© poblado
        if self.vector_store.collection.count() == 0:
            logger.warning("Vector store vac√≠o. Ejecuta: python -m src.vector_store")
    
    def analyze_intent(self, query: str) -> Dict[str, Any]:
        """Analiza la intenci√≥n de la consulta del usuario"""
        intent_prompt = f"""
        Analiza la siguiente consulta sobre la Ley 2381 de 2024 (Sistema de Protecci√≥n Social) y determina:

        1. TIPO DE CONSULTA:
        - "definition": Busca definiciones o conceptos
        - "procedure": Pregunta sobre procedimientos o tr√°mites
        - "requirement": Busca requisitos o condiciones
        - "calculation": Involucra c√°lculos de pensiones, aportes, etc.
        - "general": Consulta general o exploratoria
        - "specific_article": Busca un art√≠culo espec√≠fico

        2. PALABRAS CLAVE: Identifica los t√©rminos m√°s importantes

        3. ESPECIFICIDAD: 
        - "high": Pregunta muy espec√≠fica
        - "medium": Pregunta moderadamente espec√≠fica  
        - "low": Pregunta general o amplia

        Consulta: "{query}"

        Responde SOLO en formato JSON:
        {{
            "type": "tipo_de_consulta",
            "keywords": ["palabra1", "palabra2"],
            "specificity": "nivel",
            "suggested_search_terms": ["t√©rmino1", "t√©rmino2"]
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": intent_prompt}],
                max_tokens=500,
                temperature=0.1
            )
            
            # Extraer JSON de la respuesta
            response_text = response.choices[0].message.content.strip()
            
            # Buscar JSON en la respuesta
            if '{' in response_text and '}' in response_text:
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                json_str = response_text[json_start:json_end]
                intent_analysis = json.loads(json_str)
            else:
                # Fallback si no se puede parsear
                intent_analysis = {
                    "type": "general",
                    "keywords": [query],
                    "specificity": "medium",
                    "suggested_search_terms": [query]
                }
                
            logger.info(f"An√°lisis de intenci√≥n: {intent_analysis['type']} - {intent_analysis['specificity']}")
            return intent_analysis
            
        except Exception as e:
            logger.error(f"Error en an√°lisis de intenci√≥n: {e}")
            # Fallback b√°sico
            return {
                "type": "general",
                "keywords": [query],
                "specificity": "medium",
                "suggested_search_terms": [query]
            }
    
    def search_relevant_content(self, query: str, intent_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Busca contenido relevante basado en la consulta y an√°lisis de intenci√≥n"""
        
        # Determinar n√∫mero de resultados seg√∫n especificidad
        n_results = {
            "high": 3,
            "medium": 5,
            "low": 7
        }.get(intent_analysis["specificity"], 5)
        
        # Buscar con la consulta original
        results = self.vector_store.search(query, n_results=n_results)
        
        # Si hay t√©rminos de b√∫squeda sugeridos, hacer b√∫squedas adicionales
        if intent_analysis.get("suggested_search_terms"):
            for term in intent_analysis["suggested_search_terms"][:2]:  # M√°ximo 2 t√©rminos adicionales
                if term.lower() != query.lower():
                    additional_results = self.vector_store.search(term, n_results=3)
                    results.extend(additional_results)
        
        # Eliminar duplicados manteniendo los de mayor similitud
        seen_ids = {}
        unique_results = []
        
        for result in results:
            result_id = result['metadata'].get('article_number', result['metadata'].get('section_number', 'unknown'))
            
            if result_id not in seen_ids or result['similarity_score'] > seen_ids[result_id]['similarity_score']:
                seen_ids[result_id] = result
        
        unique_results = list(seen_ids.values())
        
        # Ordenar por relevancia
        unique_results.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # Limitar resultados finales
        return unique_results[:n_results]
    
    def generate_response(self, query: str, relevant_content: List[Dict[str, Any]], intent_analysis: Dict[str, Any]) -> str:
        """Genera respuesta usando OpenAI GPT con el contenido relevante"""
        
        # Preparar contexto
        context_parts = []
        sources_info = []
        
        for i, content in enumerate(relevant_content):
            metadata = content['metadata']
            if metadata['type'] == 'article':
                source_ref = f"Art√≠culo {metadata['article_number']}"
                context_parts.append(f"ART√çCULO {metadata['article_number']}:\n{content['content']}")
            else:
                source_ref = f"{metadata['type'].title()} {metadata.get('section_number', 'N/A')}"
                context_parts.append(f"{source_ref.upper()}:\n{content['content']}")
            
            sources_info.append({
                "reference": source_ref,
                "similarity": content['similarity_score'],
                "type": metadata['type']
            })
        
        context = "\n\n".join(context_parts)
        
        # Crear prompt personalizado seg√∫n el tipo de consulta
        system_prompt = f"""
        Eres un asistente especializado en la Ley 2381 de 2024 sobre el Sistema de Protecci√≥n Social Integral para la Vejez, Invalidez y Muerte en Colombia.

        INSTRUCCIONES:
        1. Responde √öNICAMENTE bas√°ndote en la informaci√≥n proporcionada de la ley
        2. Utiliza un lenguaje claro y accesible para cualquier persona
        3. Si la informaci√≥n no est√° en el contexto proporcionado, ind√≠calo claramente
        4. Estructura tu respuesta de manera organizada
        5. Al final de tu respuesta, incluye las referencias exactas de los art√≠culos utilizados

        TIPO DE CONSULTA DETECTADO: {intent_analysis['type']}
        ESPECIFICIDAD: {intent_analysis['specificity']}

        FORMATO DE RESPUESTA:
        [Respuesta en lenguaje natural y claro]

        **Referencias:**
        - [Lista de art√≠culos citados]
        """
        
        user_prompt = f"""
        CONTEXTO DE LA LEY 2381 DE 2024:
        {context}

        CONSULTA DEL USUARIO:
        {query}

        Por favor, responde la consulta bas√°ndote √∫nicamente en la informaci√≥n proporcionada.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            response_text = response.choices[0].message.content
            logger.info(f"Respuesta generada exitosamente para consulta sobre: {intent_analysis['type']}")
            return response_text
            
        except Exception as e:
            logger.error(f"Error generando respuesta: {e}")
            return f"Lo siento, ocurri√≥ un error al procesar tu consulta: {str(e)}"
    
    def generate_summary(self, content: List[Dict[str, Any]], topic: str) -> str:
        """Genera un resumen de m√∫ltiples art√≠culos sobre un tema espec√≠fico"""
        
        if not content:
            return "No se encontr√≥ informaci√≥n suficiente para generar un resumen."
        
        # Preparar contenido para resumen
        articles_text = []
        for item in content:
            metadata = item['metadata']
            if metadata['type'] == 'article':
                articles_text.append(f"Art√≠culo {metadata['article_number']}: {item['content']}")
        
        if not articles_text:
            return "No se encontraron art√≠culos relevantes para generar el resumen."
        
        combined_content = "\n\n".join(articles_text)
        
        summary_prompt = f"""
        Genera un resumen ejecutivo claro y organizado sobre "{topic}" bas√°ndote en los siguientes art√≠culos de la Ley 2381 de 2024:

        {combined_content}

        El resumen debe:
        1. Ser conciso pero completo
        2. Usar lenguaje accesible
        3. Estar bien estructurado
        4. Incluir los puntos m√°s importantes
        5. Mencionar los art√≠culos de referencia al final

        FORMATO:
        ## Resumen: {topic}

        [Contenido del resumen organizado en p√°rrafos]

        **Art√≠culos consultados:** [Lista de art√≠culos]
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": summary_prompt}],
                max_tokens=1500,
                temperature=0.3
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Error generando resumen: {e}")
            return f"Error al generar resumen: {str(e)}"
    
    def process_query(self, query: str, generate_summary_if_multiple: bool = True) -> QueryResult:
        """Procesa una consulta completa del usuario"""
        start_time = datetime.now()
        
        try:
            # 1. Analizar intenci√≥n
            intent_analysis = self.analyze_intent(query)
            
            # 2. Buscar contenido relevante
            relevant_content = self.search_relevant_content(query, intent_analysis)
            
            if not relevant_content:
                response = "No encontr√© informaci√≥n relevante sobre tu consulta en la Ley 2381 de 2024. ¬øPodr√≠as reformular tu pregunta o ser m√°s espec√≠fico?"
                sources = []
            else:
                # 3. Generar respuesta
                if len(relevant_content) > 3 and generate_summary_if_multiple and intent_analysis['specificity'] == 'low':
                    # Para consultas generales con muchos resultados, generar resumen
                    response = self.generate_summary(relevant_content, query)
                else:
                    # Respuesta normal
                    response = self.generate_response(query, relevant_content, intent_analysis)
                
                # Preparar informaci√≥n de fuentes
                sources = []
                for content in relevant_content:
                    metadata = content['metadata']
                    if metadata['type'] == 'article':
                        sources.append({
                            "reference": f"Art√≠culo {metadata['article_number']}",
                            "similarity_score": content['similarity_score'],
                            "type": "article"
                        })
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return QueryResult(
                response=response,
                sources=sources,
                query=query,
                timestamp=start_time,
                processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"Error procesando consulta: {e}")
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return QueryResult(
                response=f"Ocurri√≥ un error al procesar tu consulta: {str(e)}",
                sources=[],
                query=query,
                timestamp=start_time,
                processing_time=processing_time
            )

def main():
    """Funci√≥n principal para testing"""
    if not settings.OPENAI_API_KEY:
        print("‚ùå Error: OPENAI_API_KEY no configurada")
        print("   1. Obt√©n tu API key en: https://platform.openai.com/api-keys")
        print("   2. Agr√©gala al archivo .env como: OPENAI_API_KEY=tu_key_aqui")
        return
    
    agent = OpenAIAgent()
    
    # Consultas de prueba
    test_queries = [
        "¬øQu√© es el Sistema de Protecci√≥n Social?",
        "¬øCu√°les son los requisitos para la pensi√≥n de vejez?",
        "¬øC√≥mo se calculan los aportes?",
        "art√≠culo 15"
    ]
    
    print("ü§ñ Probando el agente de OpenAI...")
    print("=" * 50)
    
    for query in test_queries:
        print(f"\nüîç Consulta: {query}")
        print("-" * 30)
        
        result = agent.process_query(query)
        
        print(f"‚è±Ô∏è  Tiempo de procesamiento: {result.processing_time:.2f}s")
        print(f"üìÑ Fuentes consultadas: {len(result.sources)}")
        print(f"\nüí¨ Respuesta:\n{result.response}")
        
        if result.sources:
            print(f"\nüìö Referencias:")
            for source in result.sources:
                print(f"   - {source['reference']} (relevancia: {source['similarity_score']:.3f})")
        
        print("\n" + "=" * 50)

if __name__ == "__main__":
    main()
